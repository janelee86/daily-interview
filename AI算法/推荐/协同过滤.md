Author: Summer;     Email: huangmeihong11@sina.com
# 协同过滤(collaborative filtering)
## 直观解释
协同过滤是推荐算法中最常用的算法之一，它根据user与item的交互，发现item之间的相关性，或者发现user之间的相关性，进行推荐。比如你有位朋友看电影的爱好跟你类似，然后最近新上了《调音师》，他觉得不错，就会推荐给你，这是最简单的基于user的协同过滤算法（user-based collaboratIve filtering），还有一种是基于item的协同过滤算法（item-based collaborative filtering），比如你非常喜欢电影《当幸福来敲门的时候》，那么观影系统可能会推荐一些类似的励志片给你，比如《风雨哈佛路》等。如下主要分析user-based，item-based同理。

Collaborative filtering is one of the most commonly used algorithms in recommendation algorithms. It discovers the correlation between items or the correlation between users according to the interaction between users and items, and makes recommendations. For example, you have a friend whose hobby of watching movies is similar to yours, and recently came to "Tuner", and he thinks it is good, so he will recommend it to you. This is the simplest user-based collaborative filtering algorithm (user-based collaborative filtering algorithm). filtering), there is also an item-based collaborative filtering algorithm (item-based collaborative filtering), for example, if you like the movie "When Happiness Knocks on the Door" very much, then the viewing system may recommend some similar inspirational movies to you , such as "The Wind and Rain Harvard Road" and so on. The following mainly analyzes user-based and item-based in the same way.
## 导图
![image](https://github.com/janelee86/daily-interview/blob/master/AI%E7%AE%97%E6%B3%95/%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E5%9B%BE%E7%89%87/%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4.png)
## 核心公式
* 符号定义

* 核心公式
1. item-based CF 邻域方法预测公式


1. 偏差优化目标
$$\min _{b} \sum_{(u, i) \in K}\left(r_{(u, i)}-\mu-b_{u}-b_{i}\right)^{2}$$
其中$(u，i) \in K$表示所有的评分，$\mu$总评分均值，$b_u$为user $u$的偏差，$b_i$为item $i$ 的偏差。

1. - 加入正则项后的Funk SVD 优化公式
$$\min _{u v} \sum_{(u, i) \in k n o w n}\left(r_{u,i}-u_{u} v_{i}\right)+\lambda\left(|u|^{2}+|v|^{2}\right)$$
其中$u_u$为user $u$的偏好，即为user特征矩阵$U$的第$u$行，$v_i$为item $i$的特征，即为特征矩阵$V$的第$i$列
## 注意要点
* 相似度与距离之间的关系距离越大，相似度越小；距离越小，相似度越高。即在求解最大相似度的时候可以转为求解最小距离。
The relationship between similarity and distance The larger the distance, the smaller the similarity; the smaller the distance, the higher the similarity. That is, when solving the maximum similarity, it can be converted to the minimum distance.
* 在协同过滤中，常用的相似度函数有哪些，简要说明
  * 杰卡德相似度（Jaccard similarity）
  公式：![image]()
  $$sim_{jaccard}(u_{1}, u_{2})=\frac{ \text {items} \text { bought by } u_{1}\  and\  u_{2}}{ \text { items  bought by  } u_{1}\  or\  u_{2}}$$
  适用于二元情况，即定性情况，比如买或者没买，喜欢或者不喜欢，在数据稀疏的情况，可以转为二元应用。
  It is suitable for binary situations, that is, qualitative situations, such as buying or not buying, liking or disliking, and can be converted into binary applications when data is sparse.
    * 余弦相似度
   公式：![image](https://github.com/janelee86/daily-interview/blob/master/AI%E7%AE%97%E6%B3%95/%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E5%9B%BE%E7%89%87/%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6.png)
   考虑不同用户的评价范围不一样，比如乐天派一般评分范围一般会高于悲观的人，会将评分进行去中心化再进行计算，即修正余弦相似度，公式变为
   Considering that the evaluation ranges of different users are different, for example, optimists generally have a higher rating range than pessimists, and the ratings will be decentralized and then calculated, that is, the modified cosine similarity, the formula becomes
    * ![image](https://github.com/janelee86/daily-interview/blob/master/AI%E7%AE%97%E6%B3%95/%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E5%9B%BE%E7%89%87/%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A62.png)

    适用于定量情况，比如评分场景，要求数据具有一定的稠密度。注意如果计算一个评价很少电影的用户与一个评价很多电影的用户会导致相似度为0.
    * 皮尔森相关系数
   公式：![image](https://github.com/janelee86/daily-interview/blob/master/AI%E7%AE%97%E6%B3%95/%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E5%9B%BE%E7%89%87/%E7%9A%AE%E5%B0%94%E9%80%8A%E7%9B%B8%E4%BC%BC%E5%BA%A6.png)
  
   皮尔森系数跟修正的余弦相似度几乎一致，两者的区别在于分母上，皮尔逊系数的分母采用的评分集是两个用户的共同评分集（就是两个用户都对这个物品有评价），而修正的余弦系数则采用两个用户各自的评分集。
   The Pearson coefficient is almost the same as the modified cosine similarity. The difference between the two lies in the denominator. The scoring set used in the denominator of the Pearson coefficient is the common scoring set of two users (that is, both users have comments on this item), The modified cosine coefficients use the respective rating sets of the two users.
    * $L_{p}-norms$
   公式：$$sim(u_1,u_2) =\frac{1}{ \sqrt[p]{| r_{u_1}-r_{u_2} |^p}+1}$$
   ![image](https://github.com/janelee86/daily-interview/blob/master/AI%E7%AE%97%E6%B3%95/%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E5%9B%BE%E7%89%87/%E5%AF%B9%E7%83%AD%E9%97%A8%E5%95%86%E5%93%81%E8%BF%9B%E8%A1%8C%E6%83%A9%E7%BD%9A.png)
取不同的值对应不同的距离公式，空间距离公式存在的不足这边也存在。对数值比较敏感。
* 有了相似度测量后，那么基于邻域的推荐思路是怎样的呢？
* With the similarity measurement, what is the idea of neighborhood-based recommendation?
过滤掉被评论较少的items以及较少评价的users，然后计算完users之间的相似度后，寻找跟目标user偏好既有大量相同的items，又存在不同的items的近邻几个users(可采用K-top、阈值法、聚类等方式)，然后进行推荐。步骤如下：

(1) 选择：选出最相似几个用户，将这些用户所喜欢的物品提取出来并过滤掉目标用户已经喜欢的物品
(2) 评估：对余下的物品进行评分与相似度加权
(3) 排序：根据加权之后的值进行排序
(4) 推荐：由排序结果对目标用户进行推荐

Filter out items that are less commented on and users that are less evaluated, and then after calculating the similarity between users, look for users who have a large number of the same items as the target user's preferences and have different items. Use K-top, threshold method, clustering, etc.), and then make recommendations. Proceed as follows:

(1) Selection: Select the most similar users, extract the items that these users like and filter out the items that the target user has already liked。
(2) Evaluation: Score and weight the remaining items  
(3) Sorting: Sort according to the weighted value  
(4) Recommendation: recommend the target users based on the sorting results  


* 协同过滤算法具有特征学习的特点，试解释原理以及如何学习
1. 特征学习：把users做为行，items作为列，即得评分矩阵，通过矩阵分解的方式进行特征学习，即将评分矩阵分解，其中$U_{m,d}$为用户特征矩阵，$V_{d,n}$表示items特征矩阵，其中$d$表示对items进行$d$个主题划分。举个简单例子，比如看电影的评分矩阵划分后，$U$中每一列表示电影的一种主题成分，比如搞笑、动作等，$V$中每一行表示一个用户的偏好，比如喜欢搞笑的程度，喜欢动作的程度，值越大说明越喜欢。这样，相当于，把电影进行了主题划分，把人物偏好也进行主题划分，主题是评分矩阵潜在特征。

* Collaborative filtering algorithm has the characteristics of feature learning, try to explain the principle and how to learn

1. Feature learning: use users as rows and items as columns to obtain a rating matrix, and perform feature learning through matrix decomposition, that is, to decompose the rating matrix, where $U_{m,d}$ is the user feature matrix, $V_ {d,n}$ represents the feature matrix of items, where $d$ represents $d$ subject division of items. To give a simple example, for example, after watching a movie rating matrix, each column in $U$ represents a theme component of the movie, such as funny, action, etc., and each row in $V$ represents a user’s preference, such as those who like funny Degree, how much you like the action, the larger the value, the more you like it. In this way, it is equivalent to dividing the movie into themes and character preferences into themes. Themes are the potential features of the scoring matrix.
3. 学习方式
4. - SVD，如下
	 ![image](https://uploader.shimo.im/f/dk4h20R8bkQUajmh!thumbnail)
 奇异值分解的方式，便于处理要目标user（直接添加到用户特征矩阵的尾部即可），然而要求评分矩阵元素不能为空，因此需要事先进行填充处理，同时由于user和item的数量都比较多，矩阵分解的方式计算量大，且矩阵为静态的需要随时更新，因此实际中比较少用。
 
 The singular value decomposition method is convenient for processing the target user (just add it to the end of the user feature matrix). However, it is required that the elements of the scoring matrix cannot be empty, so it needs to be filled in advance. At the same time, due to the large number of users and items , the method of matrix decomposition is computationally intensive, and the matrix is ​​static and needs to be updated at any time, so it is rarely used in practice.
 
4. - Funk SVD， Funk SVD 是去掉SVD的$\Sigma$成分，优化如下目标函数，可通过梯度下降法，得到的$U,V$矩阵
	  
	  Funk SVD 只要利用全部有评价的信息，不需要就空值进行处理，同时可以采用梯度下降法，优化较为方便，较为常用。针对于新user、新item，协同过滤失效。
	  As long as Funk SVD uses all the evaluated information, it does not need to deal with null values. At the same time, it can use the gradient descent method, which is more convenient and commonly used for optimization. Collaborative filtering fails for new users and new items.

* 如何简单计算user偏差以及item偏差？
  

* 如何选择协同过滤算法是基于user还是基于item
* How to choose whether the collaborative filtering algorithm is based on user or item

一般，谁的量多就不选谁。然而基于user的会给推荐目标带来惊喜，选择的范围更为宽阔，而不是基于推荐目标当前的相似item。因此如果要给推荐目标意想不到的推荐，就选择基于user的方式。可以两者结合。
Generally, whoever has the most quantity will not be selected. However, based on the user, it will bring surprises to the recommendation target, and the selection range is wider, rather than based on the current similar items of the recommendation target. Therefore, if you want to give unexpected recommendations to the recommendation target, choose the user-based method. It is possible to combine both.

  
* 协同过滤的优缺点
* Pros and Cons of Collaborative Filtering
  1. 缺点：shortcoming
   (1)稀疏性—— 这是协同过滤中最大的问题，大部分数据不足只能推荐比较流行的items，因为很多人只有对少量items进行评价，而且一般items的量非常多，很难找到近邻。导致大量的user木有数据可推荐（一般推荐比较流行的items），大量的item不会被推荐
   (2)孤独用户——孤独user具有非一般的品味，难以找到近邻，所以推荐不准确
   (3) 冷启动——只有大量的评分之后，才能协同出较多信息，所以前期数据比较少，推荐相对不准确；而如果没有人进行评分，将无法被推荐
   (4)相似性——协同过滤是与内容无关的推荐，只根据用户行为，所以倾向于推荐较为流行的items。
   
   (1) Sparsity - This is the biggest problem in collaborative filtering. Most of the data is insufficient and only popular items can be recommended, because many people only evaluate a small number of items, and generally the amount of items is very large, it is difficult to find neighbors . As a result, a large number of users have no data to recommend (generally recommend popular items), and a large number of items will not be recommended
   (2) Lonely users - Lonely users have unusual tastes, and it is difficult to find neighbors, so the recommendation is not accurate
   (3) Cold start - Only after a large number of ratings can more information be collaboratively produced, so the previous data is relatively small, and the recommendation is relatively inaccurate; and if no one scores, it will not be recommended
   (4) Similarity—Collaborative filtering is a recommendation that has nothing to do with content and is only based on user behavior, so it tends to recommend more popular items.


* 优点：advantage
  	(1)不需要领域知识，存在users和items的互动，便能进行推荐
 	(2)简单易于理解
  	(3)相似度计算可预计算，预测效率高
 	(1) No domain knowledge is required, and there is interaction between users and items to make recommendations
 	(2) Simple and easy to understand
  	(3) The similarity calculation can be pre-calculated, and the prediction efficiency is high

* 协同过滤与关联规则的异同
* Similarities and differences between collaborative filtering and association rules
关联规则是不考虑tems或者使用它们的users情况下分析内容之间的关系，而协同过滤是不考虑内容直接分析items之间的关系或者users之间的关系。两者殊途同归均能用于推荐系统，但是计算方式不同。

Association rules analyze the relationship between content without considering items or users who use them, while collaborative filtering directly analyzes the relationship between items or users without considering the content. Both of them have the same goal and can be used in recommendation systems, but the calculation methods are different.

* 实践中的一些注意点，Some Notes in Practice
  (1) 过滤掉被评价较少的items
  (2) 过滤掉评价较少的users
  (3) 可用聚类方式缩小搜索空间，但是面临找不到相同偏好的用户（如果用户在分界点，被误分的情况），这种方式通过缩小搜索空间的方式优化协同过滤算法
  (4) 使用的时候，可以考虑时间范围，偏好随着时间的改变会改变
  
  (1) Filter out items that are less evaluated
  (2) Filter out users with less comments
  (3) The search space can be narrowed by clustering, but in the face of users who cannot find the same preference (if the user is at the cut-off point, they will be misclassified), this method optimizes the collaborative filtering algorithm by reducing the search space
  (4) When using, you can consider the time range, and the preference will change over time




UserCF和ItemCF优缺点的对比/Comparison of the advantages and disadvantages of UserCF and ItemCF
UserCF
性能	适用于用户较少的场合，如果用户很多，计算用户相似度矩阵代价很大	             
领域	时效性较强，用户个性化兴趣不太明显的领域	
实时性	用户有新行为，不一定造成推荐结果的立即变化	
冷启动	在新用户对很少的物品产生行为后，不能立即对他进行个性化推荐，因为用户相似度表是每隔一段时间离线计算的，	
           新物品上线后一段时间，一旦有用户对物品产生行为，就可以将新物品推荐给和对它产生行为的用户兴趣相似的其他用户	
推荐理由	很难提供令用户信服的推荐解释	

UserCF
Performance ：
	Applicable to occasions with few users. If there are many users, the cost of calculating the user similarity matrix is very high
Fields 	:
	with strong timeliness and less obvious user interests
Real-time:
	users have new behaviors, which may not necessarily cause immediate changes in the recommendation results
Cold start :
	After a new user acts on few items, personalized recommendations cannot be made immediately, because the user similarity table is calculated offline every once in a while.After a period of time after the new item is online, once a user acts on the item, the new item can be recommended to other users who have similar interests to the user who has acted on it；

Recommendation reason：
	It is difficult to provide a convincing recommendation explanation for users


ItemCF
性能    适用于物品数明显小于用户数的场合，如果物品很多（网页），计算物品相似度矩阵代价很大
领域    长尾物品丰富，用户个性化需求强烈的领域
实时性   用户有新行为，一定会导致推荐结果的实时变化，但没有办法在不离线更新物品相似度表的情况下将新物品推荐给用户
冷启动   新用户只要对一个物品产生行为，就可以给他推荐和该物品相关的其他物品
推荐理由  利用用户的历史行为给用户做推荐解释，可以令用户比较信服

Item CF  
Performance：  
	Applicable to occasions where the number of items is significantly smaller than the number of users. If there are many items (web pages), the cost of calculating the item similarity matrix is very high.  
Fields:  
	Long-tail items are abundant and users have strong individual needs  
Real-time:  
	new behaviors of users will definitely lead to real-time changes in the recommendation results, but there is no way to recommend new items to users without updating the item similarity table offline  
Cold start:   
	As long as a new user acts on an item, he can recommend other items related to the item  
Recommendation reason:  
	Use the user's historical behavior to give the user a recommendation explanation, which can make the user more convincing  


## 面试真题
使用协同过滤算法之前，数据应该如何进行预处理？How should the data be preprocessed before using the collaborative filtering algorithm?

协同过滤的方式有哪些？
如何通过相似度计算设计协同过滤推荐系统？
请谈谈你对协同过滤中特征学习的理解？
如何将协同过滤用于推荐系统？
FUNK SVD相对于SVD有哪些优势？
如何求解FUNK SVD？
请描述下协同过滤的优缺点？
